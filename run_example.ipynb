{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666f119c-4bf1-4ac7-bacc-93df31860c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Federated IDT with Voting Aggregation ===\n",
      "Dataset: EMLC0 | Weight Method: idt_quality\n",
      "IDT Params: width=8, depth=2, max_depth=None\n",
      "============================================================\n",
      "Need labels: [0, 1], max per label: 5000\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 5\n",
      "[Client 0] Label distribution: {0: 637, 1: 1000}, Total: 1637\n",
      "[Client 1] Label distribution: {0: 630}, Total: 630\n",
      "[Client 2] Label distribution: {0: 666}, Total: 666\n",
      "[Client 3] Label distribution: {1: 1000}, Total: 1000\n",
      "[Client 4] Label distribution: {0: 620}, Total: 620\n",
      "\n",
      "=== Client Training & IDT Distillation ===\n",
      "[Client 0] Training GNN...\n",
      "[Client 0] Epoch 99/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0775, acc: 0.9756\n",
      "[Client 0] Epoch 199/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0802, acc: 0.9665\n",
      "[Client 0] Epoch 299/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0993, acc: 0.9573\n",
      "[Client 0] Epoch 399/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.1160, acc: 0.9512\n",
      "[Client 0] Epoch 499/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.1221, acc: 0.9512\n",
      "[Client 0] Epoch 599/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.1255, acc: 0.9512\n",
      "[Client 0] Epoch 699/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.1280, acc: 0.9543\n",
      "[Client 0] Epoch 799/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.1298, acc: 0.9543\n",
      "[Client 0] Epoch 899/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.1317, acc: 0.9543\n",
      "[Client 0] Epoch 999/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.1331, acc: 0.9543\n",
      "[Client 0] Distilling to IDT...\n",
      "IDT Parameters: width=8, sample_size=1000, layer_depth=2, max_depth=None, ccp_alpha=0.001\n",
      "cuda:0\n",
      "[Client 0] IDT Distillation Results:\n",
      "  GCN test accuracy: 0.9543\n",
      "  IDT test accuracy: 1.0000\n",
      "  IDT F1 score:      1.0000\n",
      "  Fidelity:          0.9543\n",
      "[Client 0] IDT saved to ./saved_client_idts\\client_0_idt.pkl\n",
      "[Client 1] Training GNN...\n",
      "[Client 1] Epoch 99/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 1] Epoch 199/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 1] Epoch 299/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 1] Epoch 399/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 1] Epoch 499/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 1] Epoch 599/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 1] Epoch 699/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 1] Epoch 799/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 1] Epoch 899/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 1] Epoch 999/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 1] Distilling to IDT...\n",
      "IDT Parameters: width=8, sample_size=1000, layer_depth=2, max_depth=None, ccp_alpha=0.001\n",
      "cuda:0\n",
      "[Client 1] IDT Distillation Results:\n",
      "  GCN test accuracy: 1.0000\n",
      "  IDT test accuracy: 1.0000\n",
      "  IDT F1 score:      1.0000\n",
      "  Fidelity:          1.0000\n",
      "[Client 1] IDT saved to ./saved_client_idts\\client_1_idt.pkl\n",
      "[Client 2] Training GNN...\n",
      "[Client 2] Epoch 99/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 2] Epoch 199/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 2] Epoch 299/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 2] Epoch 399/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 2] Epoch 499/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 2] Epoch 599/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 2] Epoch 699/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 2] Epoch 799/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 2] Epoch 899/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 2] Epoch 999/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 2] Distilling to IDT...\n",
      "IDT Parameters: width=8, sample_size=1000, layer_depth=2, max_depth=None, ccp_alpha=0.001\n",
      "cuda:0\n",
      "[Client 2] IDT Distillation Results:\n",
      "  GCN test accuracy: 1.0000\n",
      "  IDT test accuracy: 1.0000\n",
      "  IDT F1 score:      1.0000\n",
      "  Fidelity:          1.0000\n",
      "[Client 2] IDT saved to ./saved_client_idts\\client_2_idt.pkl\n",
      "[Client 3] Training GNN...\n",
      "[Client 3] Epoch 99/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 3] Epoch 199/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 3] Epoch 299/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 3] Epoch 399/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 3] Epoch 499/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 3] Epoch 599/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 3] Epoch 699/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 3] Epoch 799/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 3] Epoch 899/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 3] Epoch 999/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 3] Distilling to IDT...\n",
      "IDT Parameters: width=8, sample_size=1000, layer_depth=2, max_depth=None, ccp_alpha=0.001\n",
      "cuda:0\n",
      "[Client 3] IDT Distillation Results:\n",
      "  GCN test accuracy: 1.0000\n",
      "  IDT test accuracy: 1.0000\n",
      "  IDT F1 score:      1.0000\n",
      "  Fidelity:          1.0000\n",
      "[Client 3] IDT saved to ./saved_client_idts\\client_3_idt.pkl\n",
      "[Client 4] Training GNN...\n",
      "[Client 4] Epoch 99/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 4] Epoch 199/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 4] Epoch 299/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 4] Epoch 399/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 4] Epoch 499/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 4] Epoch 599/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 4] Epoch 699/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 4] Epoch 799/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 4] Epoch 899/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 4] Epoch 999/1000 - Train loss: 0.0000, acc: 1.0000 | Val loss: 0.0000, acc: 1.0000\n",
      "[Client 4] Distilling to IDT...\n",
      "IDT Parameters: width=8, sample_size=1000, layer_depth=2, max_depth=None, ccp_alpha=0.001\n",
      "cuda:0\n",
      "[Client 4] IDT Distillation Results:\n",
      "  GCN test accuracy: 1.0000\n",
      "  IDT test accuracy: 1.0000\n",
      "  IDT F1 score:      1.0000\n",
      "  Fidelity:          1.0000\n",
      "[Client 4] IDT saved to ./saved_client_idts\\client_4_idt.pkl\n",
      "\n",
      "=== Starting Voting-based Aggregation ===\n",
      "[VotingAggregator] Initialized, results will be saved to: ./voting_results/EMLC0_idt_quality\n",
      "[VotingAggregator] Adding client IDTs...\n",
      "[Client 0] structure weight = 1.0000 (root_gini=0.4581, avg_leaf_gini=0.0000, purification=0.4581)\n",
      "[VotingAggregator] Added client 0 with weight 1.000\n",
      "  Client 0: weight=1.000, test_acc=1.000\n",
      "[Client 1] structure weight = 0.0000 (root_gini=0.0000, avg_leaf_gini=0.0000, purification=0.0000)\n",
      "[VotingAggregator] Added client 1 with weight 0.010\n",
      "  Client 1: weight=0.010, test_acc=1.000\n",
      "[Client 2] structure weight = 0.0000 (root_gini=0.0000, avg_leaf_gini=0.0000, purification=0.0000)\n",
      "[VotingAggregator] Added client 2 with weight 0.010\n",
      "  Client 2: weight=0.010, test_acc=1.000\n",
      "[Client 3] structure weight = 0.0000 (root_gini=0.0000, avg_leaf_gini=0.0000, purification=0.0000)\n",
      "[VotingAggregator] Added client 3 with weight 0.010\n",
      "  Client 3: weight=0.010, test_acc=1.000\n",
      "[Client 4] structure weight = 0.0000 (root_gini=0.0000, avg_leaf_gini=0.0000, purification=0.0000)\n",
      "[VotingAggregator] Added client 4 with weight 0.010\n",
      "  Client 4: weight=0.010, test_acc=1.000\n",
      "\n",
      "[VotingAggregator] Creating global IDT from voting...\n",
      "[VotingAggregator] Creating global IDT from voting results...\n",
      "[VotingAggregator] Normalized client weights: [0.9615384607311388, 0.009615384817215312, 0.009615384817215312, 0.009615384817215312, 0.009615384817215312]\n",
      "[VotingAggregator] Processing 5 training batches...\n",
      "  Batch 1: 1309 samples processed\n",
      "  Batch 2: 504 samples processed\n",
      "  Batch 3: 532 samples processed\n",
      "  Batch 4: 800 samples processed\n",
      "  Batch 5: 496 samples processed\n",
      "\n",
      "[VotingAggregator] Voting Analysis:\n",
      "  Total samples: 3641\n",
      "  Voting accuracy vs true labels: 1.0000\n",
      "  True label distribution: {0: 1997, 1: 1644}\n",
      "  Voted label distribution: {0: 1997, 1: 1644}\n",
      "[VotingAggregator] Combining all batches...\n",
      "[VotingAggregator] Generating values for IDT training...\n",
      "[VotingAggregator] Training new IDT with voted labels...\n",
      "[VotingAggregator] Global IDT training completed!\n",
      "  IDT structure: 48 layers + output layer\n",
      "[VotingAggregator] Global IDT creation completed in 51.26 seconds\n",
      "\n",
      "=== Evaluation ===\n",
      "\n",
      "[VotingAggregator] Final Results:\n",
      "  Global IDT accuracy:   1.0000\n",
      "  Global IDT F1 score:   1.0000\n",
      "  Global IDT Precision:  1.0000\n",
      "  Global IDT Recall:     1.0000\n",
      "  Direct voting accuracy:1.0000\n",
      "  Accuracy improvement:  +0.0000\n",
      "\n",
      "=== Visualization ===\n",
      "Output layer decision tree saved to: ./voting_results/EMLC0_idt_quality/client_0_output.png\n",
      "[Client 0] Output layer saved to ./voting_results/EMLC0_idt_quality/client_0_output.png\n",
      "[Client 0] Full IDT structure saved to ./voting_results/EMLC0_idt_quality/client_0_full.png\n",
      "Output layer decision tree saved to: ./voting_results/EMLC0_idt_quality/client_1_output.png\n",
      "[Client 1] Output layer saved to ./voting_results/EMLC0_idt_quality/client_1_output.png\n",
      "[Client 1] Full IDT structure saved to ./voting_results/EMLC0_idt_quality/client_1_full.png\n",
      "Output layer decision tree saved to: ./voting_results/EMLC0_idt_quality/client_2_output.png\n",
      "[Client 2] Output layer saved to ./voting_results/EMLC0_idt_quality/client_2_output.png\n",
      "[Client 2] Full IDT structure saved to ./voting_results/EMLC0_idt_quality/client_2_full.png\n",
      "Output layer decision tree saved to: ./voting_results/EMLC0_idt_quality/client_3_output.png\n",
      "[Client 3] Output layer saved to ./voting_results/EMLC0_idt_quality/client_3_output.png\n",
      "[Client 3] Full IDT structure saved to ./voting_results/EMLC0_idt_quality/client_3_full.png\n",
      "Output layer decision tree saved to: ./voting_results/EMLC0_idt_quality/client_4_output.png\n",
      "[Client 4] Output layer saved to ./voting_results/EMLC0_idt_quality/client_4_output.png\n",
      "[Client 4] Full IDT structure saved to ./voting_results/EMLC0_idt_quality/client_4_full.png\n",
      "\n",
      "=== Saving Results ===\n",
      "\n",
      "[VotingAggregator] Saving results to ./voting_results/EMLC0_idt_quality...\n",
      "  Global IDT saved to ./voting_results/EMLC0_idt_quality\\global_idt.pkl\n",
      "  IDT structure saved to ./voting_results/EMLC0_idt_quality\\global_idt_structure.png\n",
      "Output layer decision tree saved to: ./voting_results/EMLC0_idt_quality\\global_idt_output_layer.png\n",
      "  Output layer saved to ./voting_results/EMLC0_idt_quality\\global_idt_output_layer.png\n",
      "  Aggregation info saved to ./voting_results/EMLC0_idt_quality\\aggregation_info.json\n",
      "  Evaluation results saved to ./voting_results/EMLC0_idt_quality\\evaluation_results.json\n",
      "[VotingAggregator] All results saved successfully!\n",
      "[VotingAggregator] All results saved successfully\n",
      "\n",
      "=== Final Summary ===\n",
      "Aggregation method: Voting-based\n",
      "Number of clients: 5\n",
      "Client weights: ['0.962', '0.010', '0.010', '0.010', '0.010']\n",
      "Global IDT layers: 48\n",
      "Voting accuracy improvement: 0.000\n",
      "\n",
      "=== Federated Voting Aggregation Completed ===\n",
      "\n",
      "=== Running Membership Inference Attack ===\n",
      "[Client 0] MIA Attack\n",
      "[MIA-loss] Attack model AUC: 0.5000\n",
      "[Client 0] MIA attack completed\n",
      "[Client 1] MIA Attack\n",
      "[MIA-loss] Attack model AUC: 0.5000\n",
      "[Client 1] MIA attack completed\n",
      "[Client 2] MIA Attack\n",
      "[MIA-loss] Attack model AUC: 0.5000\n",
      "[Client 2] MIA attack completed\n",
      "[Client 3] MIA Attack\n",
      "[MIA-loss] Attack model AUC: 0.5000\n",
      "[Client 3] MIA attack completed\n",
      "[Client 4] MIA Attack\n",
      "[MIA-loss] Attack model AUC: 0.5000\n",
      "[Client 4] MIA attack completed\n",
      "\n",
      "=== Federated Learning Completed ===\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.argv = [sys.argv[0]]\n",
    "\n",
    "import torch\n",
    "import time\n",
    "from argparse import ArgumentParser\n",
    "from data.dataset import data_label_skew\n",
    "from model.client import GNNClient\n",
    "from model.aggregate.idt_voting import SimpleVotingIDTAggregator\n",
    "from model.idt import get_activations\n",
    "from utils.mia import MIAttacker\n",
    "from torch_geometric.data import Batch\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def run_federated_voting(args):\n",
    "    # 设置标签分布\n",
    "    label_allocation = {\n",
    "        0: [0, 1],\n",
    "        1: [0],\n",
    "        2: [0],\n",
    "        3: [1],\n",
    "        4: [0],\n",
    "    }\n",
    "    num_features, num_classes, train_loaders, val_loaders, train_val_batches, test_batches = data_label_skew(\n",
    "        args.dataset,\n",
    "        kfold=args.kfold,\n",
    "        seed=args.seed,\n",
    "        return_split=True,\n",
    "        label_allocation=label_allocation,\n",
    "        samples_per_label=args.samples_per_label\n",
    "    )\n",
    "\n",
    "    # 初始化客户端\n",
    "    clients = []\n",
    "    for cid in range(args.kfold):\n",
    "        bundle = (num_features, num_classes,\n",
    "                  train_loaders[cid], val_loaders[cid],\n",
    "                  train_val_batches[cid], test_batches[cid])\n",
    "        client = GNNClient(cid, bundle, args, device=cid % args.devices)\n",
    "        clients.append(client)\n",
    "\n",
    "    # 本地训练 + 蒸馏为 IDT\n",
    "    print(\"\\n=== Client Training & IDT Distillation ===\")\n",
    "    for client in clients:\n",
    "        print(f\"[Client {client.client_id}] Training GNN...\")\n",
    "        client.train(conv=\"GCN\")\n",
    "        print(f\"[Client {client.client_id}] Distilling to IDT...\")\n",
    "        client.distill_to_idt(use_pred=True)\n",
    "\n",
    "        # 检查 IDT 蒸馏结果\n",
    "        test_batch = client.test_batch\n",
    "        GCN = client.model\n",
    "        GCN.eval()\n",
    "        with torch.no_grad():\n",
    "            dev = next(GCN.parameters()).device\n",
    "            print(dev)\n",
    "            tb = client.test_batch.to(dev)\n",
    "            logits = GCN(tb)\n",
    "        acc = (logits.argmax(-1) == tb.y).float().mean().item()\n",
    "\n",
    "        print(f\"[Client {client.client_id}] IDT Distillation Results:\")\n",
    "        print(f\"  GCN test accuracy: {acc:.4f}\")\n",
    "        print(f\"  IDT test accuracy: {client.idt.accuracy(test_batch):.4f}\")\n",
    "        print(f\"  IDT F1 score:      {client.idt.f1_score(test_batch):.4f}\")\n",
    "        print(f\"  Fidelity:          {client.idt.fidelity(test_batch, GCN):.4f}\")\n",
    "\n",
    "        # 保存每个客户端的IDT到本地文件\n",
    "        save_dir = getattr(args, 'save_dir', './saved_client_idts')\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        idt_save_path = os.path.join(save_dir, f'client_{client.client_id}_idt.pkl')\n",
    "        with open(idt_save_path, 'wb') as f:\n",
    "            pickle.dump(client.idt, f)\n",
    "        print(f\"[Client {client.client_id}] IDT saved to {idt_save_path}\")\n",
    "\n",
    "    # ================== 投票聚合 ==================\n",
    "    print(\"\\n=== Starting Voting-based Aggregation ===\")\n",
    "\n",
    "    # 创建投票聚合器\n",
    "    aggregator = SimpleVotingIDTAggregator(\n",
    "        save_dir=f\"./voting_results/{args.dataset}_{args.weight_method}\"\n",
    "    )\n",
    "\n",
    "    # 添加客户端IDT到聚合器\n",
    "    print(\"[VotingAggregator] Adding client IDTs...\")\n",
    "    for client in clients:\n",
    "        if hasattr(client, 'idt') and client.idt is not None:\n",
    "            # 计算客户端权重\n",
    "            client_weight = calculate_client_weight(client, args.weight_method)\n",
    "\n",
    "            client_info = {\n",
    "                'client_id': client.client_id,\n",
    "                'data_size': len(client.train_loader.dataset) if hasattr(client, 'train_loader') else 0,\n",
    "                'accuracy': getattr(client, 'best_accuracy', 0.0),\n",
    "                'test_accuracy': client.idt.accuracy(client.test_batch),\n",
    "                'weight_method': args.weight_method\n",
    "            }\n",
    "\n",
    "            aggregator.add_client_idt(client.idt, client_weight, client_info)\n",
    "            print(f\"  Client {client.client_id}: weight={client_weight:.3f}, \"\n",
    "                  f\"test_acc={client_info['test_accuracy']:.3f}\")\n",
    "\n",
    "    # 定义values生成器\n",
    "    def values_generator(batch):\n",
    "        \"\"\"生成IDT训练所需的values\"\"\"\n",
    "        # 使用第一个客户端的模型生成values（可以改进为ensemble）\n",
    "        reference_model = clients[0].model\n",
    "        return get_activations(batch, reference_model)\n",
    "\n",
    "    # 基于投票创建全局IDT\n",
    "    print(\"\\n[VotingAggregator] Creating global IDT from voting...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    global_idt = aggregator.create_global_idt(\n",
    "        train_val_batches,  # 使用训练+验证数据\n",
    "        values_generator,\n",
    "        idt_params={\n",
    "            'width': args.width,\n",
    "            'sample_size': args.sample_size,\n",
    "            'layer_depth': args.layer_depth,\n",
    "            'max_depth': args.max_depth,\n",
    "            'ccp_alpha': args.ccp_alpha\n",
    "        }\n",
    "    )\n",
    "\n",
    "    aggregation_time = time.time() - start_time\n",
    "    print(f\"[VotingAggregator] Global IDT creation completed in {aggregation_time:.2f} seconds\")\n",
    "\n",
    "    # ================== 评估 ==================\n",
    "    print(\"\\n=== Evaluation ===\")\n",
    "\n",
    "    # 评估全局IDT性能\n",
    "    evaluation_results = aggregator.evaluate_global_idt(test_batches)\n",
    "\n",
    "    print(f\"\\n[VotingAggregator] Final Results:\")\n",
    "    print(f\"  Global IDT accuracy:   {evaluation_results['global_idt_accuracy']:.4f}\")\n",
    "    print(f\"  Global IDT F1 score:   {evaluation_results['global_idt_f1']:.4f}\")\n",
    "    print(f\"  Global IDT Precision:  {evaluation_results['global_idt_precision']:.4f}\")\n",
    "    print(f\"  Global IDT Recall:     {evaluation_results['global_idt_recall']:.4f}\")\n",
    "    print(f\"  Direct voting accuracy:{evaluation_results['direct_voting_accuracy']:.4f}\")\n",
    "    print(f\"  Accuracy improvement:  {evaluation_results['improvement']:+.4f}\")\n",
    "\n",
    "    # ================== 可视化 ==================\n",
    "    print(\"\\n=== Visualization ===\")\n",
    "\n",
    "    # 保存客户端IDT可视化\n",
    "    for client in clients:\n",
    "        try:\n",
    "            # 保存输出层\n",
    "            output_path = f\"./voting_results/{args.dataset}_{args.weight_method}/client_{client.client_id}_output.png\"\n",
    "            client.idt.save_output_layer_spacious(output_path, figsize=(12, 8))\n",
    "            print(f\"[Client {client.client_id}] Output layer saved to {output_path}\")\n",
    "\n",
    "            # 保存完整IDT结构（可选）\n",
    "            if hasattr(client.idt, 'save_image'):\n",
    "                full_path = f\"./voting_results/{args.dataset}_{args.weight_method}/client_{client.client_id}_full.png\"\n",
    "                client.idt.prune()\n",
    "                client.idt.save_image(full_path)\n",
    "                print(f\"[Client {client.client_id}] Full IDT structure saved to {full_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Client {client.client_id}] Visualization failed: {e}\")\n",
    "\n",
    "    # 保存全局IDT可视化\n",
    "    # ================== 分析与保存 ==================\n",
    "    print(\"\\n=== Saving Results ===\")\n",
    "\n",
    "    # 保存所有结果\n",
    "    try:\n",
    "        aggregator.save_results(evaluation_results)\n",
    "        print(\"[VotingAggregator] All results saved successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"[VotingAggregator] Save results failed: {e}\")\n",
    "\n",
    "    # 打印最终摘要\n",
    "    print(\"\\n=== Final Summary ===\")\n",
    "    try:\n",
    "        summary = aggregator.get_summary()\n",
    "        print(f\"Aggregation method: Voting-based\")\n",
    "        print(f\"Number of clients: {summary['num_clients']}\")\n",
    "        print(f\"Client weights: {[f'{w:.3f}' for w in summary['client_weights']]}\")\n",
    "        print(f\"Global IDT layers: {summary.get('global_idt_info', {}).get('num_layers', 'Unknown')}\")\n",
    "        print(\n",
    "            f\"Voting accuracy improvement: {summary.get('voting_analysis', {}).get('voted_balance_score', 0) - summary.get('voting_analysis', {}).get('true_balance_score', 0):.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Summary generation failed: {e}\")\n",
    "\n",
    "    print(\"\\n=== Federated Voting Aggregation Completed ===\")\n",
    "\n",
    "    # =================== MIA Attack部分 ===================\n",
    "    # 收集有效的客户端IDT\n",
    "    valid_clients = []\n",
    "    for client in clients:\n",
    "        if (hasattr(client, 'idt') and client.idt is not None and\n",
    "                hasattr(client.idt, 'out_layer') and client.idt.out_layer is not None):\n",
    "            valid_clients.append(client)\n",
    "\n",
    "    print(\"\\n=== Running Membership Inference Attack ===\")\n",
    "    try:\n",
    "        attacker = MIAttacker()\n",
    "        for client in valid_clients:\n",
    "            print(f\"[Client {client.client_id}] MIA Attack\")\n",
    "            try:\n",
    "                # 获取训练数据作为成员数据（1/20采样）\n",
    "                train_data = next(iter(train_loaders[client.client_id]))\n",
    "                train_data_list = train_data.to_data_list()\n",
    "                num_members = max(1, len(train_data_list) // 20)\n",
    "                member_data = train_data_list[:num_members]\n",
    "                member_batch = Batch.from_data_list(member_data)\n",
    "\n",
    "                # 获取测试数据作为非成员数据（数量 = num_members）\n",
    "                test_data_list = test_batches[client.client_id].to_data_list()\n",
    "                nonmember_data = test_data_list[:num_members]\n",
    "                nonmember_batch = Batch.from_data_list(nonmember_data)\n",
    "\n",
    "                attacker.train_attack_model(client.idt, member_batch, nonmember_batch)\n",
    "                print(f\"[Client {client.client_id}] MIA attack completed\")\n",
    "            except Exception as e:\n",
    "                print(f\"[Client {client.client_id}] MIA attack failed: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"MIA setup failed: {str(e)}\")\n",
    "\n",
    "    print(\"\\n=== Federated Learning Completed ===\")\n",
    "\n",
    "    return clients, global_idt\n",
    "\n",
    "\n",
    "def calculate_client_weight(client, weight_method):\n",
    "    \"\"\"计算客户端权重\"\"\"\n",
    "    if weight_method == 'uniform':\n",
    "        return 1.0\n",
    "\n",
    "    elif weight_method == 'data_size':\n",
    "        data_size = len(client.train_loader.dataset) if hasattr(client, 'train_loader') else 1\n",
    "        return float(data_size)\n",
    "\n",
    "    elif weight_method == 'idt_quality':\n",
    "        # 基于IDT结构的权重计算\n",
    "        if not hasattr(client, 'idt') or client.idt is None:\n",
    "            return 0.1  # 如果没有IDT，给予最低权重\n",
    "\n",
    "        if client.idt.out_layer is None or client.idt.out_layer.dt is None:\n",
    "            return 0.1  # 如果没有输出层决策树，给予最低权重\n",
    "\n",
    "        # 使用你的结构权重计算方法\n",
    "        final_weight = calculate_client_weight_by_structure(client)\n",
    "        return float(max(0.01, final_weight))  # 确保最小权重为0.01\n",
    "\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "\n",
    "def calculate_client_weight_by_structure(client):\n",
    "    \"\"\"\n",
    "    根据客户端IDT输出层的结构性信息分配权重：\n",
    "    - 根节点 impurity 越高，叶节点 impurity 越低 → 模型更可信。\n",
    "\n",
    "    返回值范围在 [0, 1]，可作为投票时的权重。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dt = client.idt.out_layer.dt\n",
    "        tree = dt.tree_\n",
    "\n",
    "        # 根节点 impurity\n",
    "        root_gini = tree.impurity[0]\n",
    "\n",
    "        # 找出叶节点 (修正：使用 -1，这是sklearn中TREE_LEAF的值)\n",
    "        leaf_mask = tree.children_left == -1\n",
    "        leaf_ginis = tree.impurity[leaf_mask]\n",
    "        leaf_weights = tree.n_node_samples[leaf_mask]\n",
    "\n",
    "        # 检查是否有叶节点\n",
    "        if len(leaf_ginis) == 0:\n",
    "            print(f\"[Client {client.client_id}] No leaf nodes found\")\n",
    "            return 0.0\n",
    "\n",
    "        # 计算加权平均叶节点 Gini\n",
    "        avg_leaf_gini = np.average(leaf_ginis, weights=leaf_weights)\n",
    "\n",
    "        # 纯化得分 = 根 impurity - 平均叶 impurity\n",
    "        purification_score = root_gini - avg_leaf_gini\n",
    "\n",
    "        # 归一化到 [0, 1]\n",
    "        normalized_score = purification_score / (root_gini + 1e-8)\n",
    "        normalized_score = max(0.0, min(1.0, normalized_score))\n",
    "\n",
    "        print(f\"[Client {client.client_id}] structure weight = {normalized_score:.4f} \"\n",
    "              f\"(root_gini={root_gini:.4f}, avg_leaf_gini={avg_leaf_gini:.4f}, \"\n",
    "              f\"purification={purification_score:.4f})\")\n",
    "\n",
    "        return float(normalized_score)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Client {client.client_id}] Failed to compute structure weight: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser()\n",
    "\n",
    "    # 数据和模型\n",
    "    parser.add_argument('--dataset', type=str, default='EMLC0')\n",
    "    parser.add_argument('--kfold', type=int, default=5)\n",
    "    parser.add_argument('--seed', type=int, default=42)\n",
    "    parser.add_argument('--layers', type=int, default=6)\n",
    "    parser.add_argument('--dim', type=int, default=128)\n",
    "    parser.add_argument('--activation', type=str, default='ReLU')\n",
    "    parser.add_argument('--pooling', type=str, default='mean')\n",
    "    parser.add_argument('--lr', type=float, default=1e-3)\n",
    "    parser.add_argument('--max_steps', type=int, default=1000)\n",
    "    parser.add_argument('--width', type=int, default=8)\n",
    "    parser.add_argument('--sample_size', type=int, default=1000)\n",
    "    parser.add_argument('--layer_depth', type=int, default=2)\n",
    "    parser.add_argument('--max_depth', type=int, default=None)\n",
    "    parser.add_argument('--ccp_alpha', type=float, default=1e-3)\n",
    "    parser.add_argument('--devices', type=int, default=1)\n",
    "    parser.add_argument('--samples_per_label', type=int, default=1000)\n",
    "\n",
    "    # 聚合参数 - 修改为适用于投票方法\n",
    "    parser.add_argument('--weight_method', type=str, default='idt_quality',\n",
    "                        choices=['uniform', 'data_size', 'idt_quality'],\n",
    "                        help='Method for calculating client weights in voting')\n",
    "\n",
    "    parser.add_argument('--aggregation_method', type=str, default='voting',\n",
    "                        help='Now using voting-based aggregation')\n",
    "    parser.add_argument('--similarity_threshold', type=float, default=0.8,\n",
    "                        help='Not used in voting method but kept for compatibility')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    print(\"=== Federated IDT with Voting Aggregation ===\")\n",
    "    print(f\"Dataset: {args.dataset} | Weight Method: {args.weight_method}\")\n",
    "    print(f\"IDT Params: width={args.width}, depth={args.layer_depth}, max_depth={args.max_depth}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    run_federated_voting(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bd4be2-c743-4e8f-b2d2-5f62218f564d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
